{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import codecs\n",
    "import spacy\n",
    "from pattern.en import conjugate\n",
    "coref_nlp = spacy.load('en_coref_md')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coreference(text):\n",
    "    pronoun = ['we all','i', 'you', 'we', 'they', 'he', 'she', 'it', 'me', 'your', 'his', 'her', 'him', 'myself', 'our', 'himself', 'ourselves','this guy']\n",
    "    pronoun.sort(key=len)\n",
    "    doc = coref_nlp(text)\n",
    "    if doc._.has_coref:\n",
    "        for coref in doc._.coref_clusters:\n",
    "            main = None\n",
    "            if str(coref.main).lower() in pronoun:\n",
    "                for mention in coref.mentions:\n",
    "                    if not str(mention).lower() in pronoun:\n",
    "                        main = str(mention)\n",
    "                if main == None:\n",
    "                    continue\n",
    "            for mention in coref.mentions:\n",
    "                text = text.replace(f\" {str(mention)} \",f\" {str(main)}\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_verb(token):\n",
    "    tag = token.tag_\n",
    "    res = token.text\n",
    "    if tag == 'VBP' or tag == 'VB':\n",
    "        res = conjugate(res, '3sg')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pronoun(speaker, text):\n",
    "    if text == \"You're welcome .\" or text == 'Thank you .' or text == 'The pleasure is mine .':\n",
    "        return text\n",
    "    speakers = [\"Mr.One\", \"Mr.Two\"]\n",
    "    you = speakers[(speakers.index(speaker) + 1) % 2]\n",
    "    text = text.replace('don ’ t', 'do not')\n",
    "    text = text.replace('your ', f\"{you}'s \")\n",
    "    text = text.replace('Your ', f\"{you}'s \")\n",
    "    text = text.replace(\" ’ s \", f\"'s \")\n",
    "    text = text.replace(\" ’ Ve \", f\" have \")\n",
    "    text = text.replace(\" ’ re \", f\" are \")\n",
    "    doc = nlp(text)\n",
    "    verb = None\n",
    "    text_list = []\n",
    "    for i in range(len(doc)):\n",
    "        if verb != None:\n",
    "            verb = None\n",
    "            continue\n",
    "        token = doc[i]\n",
    "        word = str(token.text)\n",
    "        index = token.i\n",
    "        if word == \"n't\":\n",
    "            word = 'not'\n",
    "        if word == \"'ll\":\n",
    "            word = 'will'\n",
    "        if word == \"'s\" and token.pos_ == 'VERB':\n",
    "            word = 'is'\n",
    "        if word == \"'d\":\n",
    "            word = token.lemma_\n",
    "        if str(token.pos_) == 'PRON':\n",
    "            if word.lower() == 'i' or word.lower() == 'me':\n",
    "                word = f'{speaker}'\n",
    "            elif word.lower() in ['we', 'us', 'our']:\n",
    "                    word = f\"Mr.A and Mr.B\"\n",
    "            elif word.lower() == 'you':\n",
    "                is_you_trans = True\n",
    "                try:\n",
    "                    is_you_trans = not(doc[index-1].text.lower() == 'thank')\n",
    "                except:\n",
    "                    pass\n",
    "                if is_you_trans:\n",
    "                    word = f'{you}'\n",
    "            elif word.lower() == 'my':\n",
    "                word = f\"{speaker}'s\"\n",
    "            elif word.lower() == 'myself':\n",
    "                word = f'by {speaker}'\n",
    "            elif word.lower() == 'yourself':\n",
    "                word = f'by {you}'\n",
    "            elif word.lower() == 'your':\n",
    "                word = f\"{you}'s\"\n",
    "            if str(token.dep_) == 'nsubj' and str(token.text.lower()) != 'we':\n",
    "                if index != 0:\n",
    "                    if doc[index-1].tag_ in ['VBP','VB']:\n",
    "                        if not ' ' in text_list[-1]:\n",
    "                            f_verb = transform_verb(doc[index-1])\n",
    "                            text_list = text_list[:-1]\n",
    "                            word = f_verb + ' ' + word\n",
    "#                             print('before',text_list + [word])\n",
    "                if index != len(doc) - 1:\n",
    "                    is_question = False\n",
    "                    if index != 0:\n",
    "                        is_question = (str(doc[index-1].tag_)== 'MD')\n",
    "                        is_question = is_question or (str(doc[index-1].text).lower() in ['does', 'is'])\n",
    "                    if not is_question:\n",
    "                        if doc[index+1].tag_ in ['VBP','VB']:\n",
    "                            verb = transform_verb(doc[index+1])\n",
    "                            word = word + ' ' + verb\n",
    "                            \n",
    "\n",
    "        text_list.append(str(word))\n",
    "    res = \" \".join(text_list)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dialogues(lines):\n",
    "    turn = 1\n",
    "    dialogues = []\n",
    "    texts = \"\"\n",
    "    original_lines = lines\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        text = line[line.index(':')+2:].strip() \n",
    "        texts += text + '\\n'\n",
    "    coref_texts = coreference(texts)\n",
    "    lines = coref_texts.strip().split('\\n')\n",
    "    for i in range(len(lines)):\n",
    "        line = original_lines[i]\n",
    "#         print(lines[i])\n",
    "        speaker = line[:1]\n",
    "        if speaker == 'A':\n",
    "            speaker = 'Mr.One'\n",
    "        if speaker == 'B':\n",
    "            speaker = 'Mr.Two'\n",
    "        open_paren_index = line.index('(')\n",
    "        close_paren_index = line.index(')')\n",
    "        act = line[open_paren_index+1:close_paren_index]\n",
    "        text = transform_pronoun(speaker, lines[i])\n",
    "        doc = nlp(text)\n",
    "        tokens = [t.text for t in doc]\n",
    "        pos = [t.pos_ for t in doc]\n",
    "        tags = [t.tag_ for t in doc]\n",
    "        dialogue = {\n",
    "            'speaker': speaker,\n",
    "            'turn': turn,\n",
    "            'act': act,\n",
    "            'text': tokens,\n",
    "            'tags': tags,\n",
    "            'pos':pos\n",
    "        }\n",
    "        dialogues.append(dialogue)\n",
    "        turn += 1\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(in_filename, inpath):\n",
    "    in_filename = os.path.abspath(f\"{inpath}\\\\{in_filename}\")\n",
    "    with codecs.open(in_filename, \"r\",'utf8') as infile:\n",
    "        lines = infile.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writefile(out_filename, data, outpath):\n",
    "    in_filename = os.path.abspath(f\"{outpath}\\\\{out_filename}\")\n",
    "    with open(out_filename, 'wb') as outfile:\n",
    "        pickle.dump(data,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filenames=None):\n",
    "    inpath = 'corpus'\n",
    "    outpath = 'pos_token2'\n",
    "    if filenames == None:\n",
    "        filenames = [f for f in os.listdir(inpath) if os.path.isfile(os.path.join(inpath, f))]\n",
    "#     print(filenames[0])\n",
    "    counter = 1\n",
    "    for in_filename in filenames:\n",
    "        out_filename = f'{outpath}/{in_filename[:-4]}.pickle'\n",
    "        lines = readfile(in_filename, inpath)\n",
    "        dialogues = get_dialogues(lines)\n",
    "#         print(dialogues)\n",
    "        writefile(out_filename, dialogues, outpath)\n",
    "        if counter % 100 == 0:\n",
    "            print(f'{counter}/{len(filenames)}')\n",
    "        counter += 1\n",
    "#         print(out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'speaker': 'Mr.One', 'turn': 1, 'act': 'directive', 'text': ['So', 'None', ',', 'how', 'about', 'getting', 'some', 'coffee', 'for', 'tonight', '?'], 'tags': ['RB', 'NN', ',', 'WRB', 'IN', 'VBG', 'DT', 'NN', 'IN', 'NN', '.'], 'pos': ['ADV', 'NOUN', 'PUNCT', 'ADV', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'PUNCT']}, {'speaker': 'Mr.Two', 'turn': 2, 'act': 'commissive', 'text': ['Coffee', '?', 'Mr', '.', 'Two', 'does', 'not', 'honestly', 'like', 'that', 'kind', 'of', 'stuff', '.'], 'tags': ['NN', '.', 'NNP', '.', 'CD', 'VBZ', 'RB', 'RB', 'VB', 'DT', 'NN', 'IN', 'NN', '.'], 'pos': ['NOUN', 'PUNCT', 'PROPN', 'PUNCT', 'NUM', 'VERB', 'ADV', 'ADV', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'PUNCT']}, {'speaker': 'Mr.One', 'turn': 3, 'act': 'directive', 'text': ['Come', 'on', ',', 'Mr', '.', 'Two', 'can', 'at', 'least', 'try', 'a', 'little', ',', 'besides', 'Mr', '.', 'Two', \"'s\", 'cigarette', '.'], 'tags': ['VB', 'RP', ',', 'NNP', '.', 'CD', 'MD', 'IN', 'JJS', 'VB', 'DT', 'JJ', ',', 'IN', 'NNP', '.', 'CD', 'POS', 'NN', '.'], 'pos': ['VERB', 'PART', 'PUNCT', 'PROPN', 'PUNCT', 'NUM', 'VERB', 'ADP', 'ADJ', 'VERB', 'DET', 'ADJ', 'PUNCT', 'ADP', 'PROPN', 'PUNCT', 'NUM', 'PART', 'NOUN', 'PUNCT']}, {'speaker': 'Mr.Two', 'turn': 4, 'act': 'inform', 'text': ['What', 'is', 'wrong', 'with', 'that', '?', 'Cigarette', 'is', 'the', 'thing', 'Mr', '.', 'Two', 'goes', 'crazy', 'for', '.'], 'tags': ['WP', 'VBZ', 'JJ', 'IN', 'DT', '.', 'NN', 'VBZ', 'DT', 'NN', 'NNP', '.', 'CD', 'VBZ', 'JJ', 'IN', '.'], 'pos': ['NOUN', 'VERB', 'ADJ', 'ADP', 'DET', 'PUNCT', 'NOUN', 'VERB', 'DET', 'NOUN', 'PROPN', 'PUNCT', 'NUM', 'VERB', 'ADJ', 'ADP', 'PUNCT']}, {'speaker': 'Mr.One', 'turn': 5, 'act': 'inform', 'text': ['Not', 'for', 'Mr', '.', 'One', ',', 'None', '.'], 'tags': ['RB', 'IN', 'NNP', '.', 'CD', ',', 'NN', '.'], 'pos': ['ADV', 'ADP', 'PROPN', 'PUNCT', 'NUM', 'PUNCT', 'NOUN', 'PUNCT']}]\n"
     ]
    }
   ],
   "source": [
    "out_filename= 'pos_token2/1.pickle'\n",
    "with open(out_filename, 'rb') as outfile:\n",
    "    data = pickle.load(outfile)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/13118\n",
      "200/13118\n",
      "300/13118\n",
      "400/13118\n",
      "500/13118\n",
      "600/13118\n",
      "700/13118\n",
      "800/13118\n",
      "900/13118\n",
      "1000/13118\n",
      "1100/13118\n",
      "1200/13118\n",
      "1300/13118\n",
      "1400/13118\n",
      "1500/13118\n",
      "1600/13118\n",
      "1700/13118\n",
      "1800/13118\n",
      "1900/13118\n",
      "2000/13118\n",
      "2100/13118\n",
      "2200/13118\n",
      "2300/13118\n",
      "2400/13118\n",
      "2500/13118\n",
      "2600/13118\n",
      "2700/13118\n",
      "2800/13118\n",
      "2900/13118\n",
      "3000/13118\n",
      "3100/13118\n",
      "3200/13118\n",
      "3300/13118\n",
      "3400/13118\n",
      "3500/13118\n",
      "3600/13118\n",
      "3700/13118\n",
      "3800/13118\n",
      "3900/13118\n",
      "4000/13118\n",
      "4100/13118\n",
      "4200/13118\n",
      "4300/13118\n",
      "4400/13118\n",
      "4500/13118\n",
      "4600/13118\n",
      "4700/13118\n",
      "4800/13118\n",
      "4900/13118\n",
      "5000/13118\n",
      "5100/13118\n",
      "5200/13118\n",
      "5300/13118\n",
      "5400/13118\n",
      "5500/13118\n",
      "5600/13118\n",
      "5700/13118\n",
      "5800/13118\n",
      "5900/13118\n",
      "6000/13118\n",
      "6100/13118\n",
      "6200/13118\n",
      "6300/13118\n",
      "6400/13118\n",
      "6500/13118\n",
      "6600/13118\n",
      "6700/13118\n",
      "6800/13118\n",
      "6900/13118\n",
      "7000/13118\n",
      "7100/13118\n",
      "7200/13118\n",
      "7300/13118\n",
      "7400/13118\n",
      "7500/13118\n",
      "7600/13118\n",
      "7700/13118\n",
      "7800/13118\n",
      "7900/13118\n",
      "8000/13118\n",
      "8100/13118\n",
      "8200/13118\n",
      "8300/13118\n",
      "8400/13118\n",
      "8500/13118\n",
      "8600/13118\n",
      "8700/13118\n",
      "8800/13118\n",
      "8900/13118\n",
      "9000/13118\n",
      "9100/13118\n",
      "9200/13118\n",
      "9300/13118\n",
      "9400/13118\n",
      "9500/13118\n",
      "9600/13118\n",
      "9700/13118\n",
      "9800/13118\n",
      "9900/13118\n",
      "10000/13118\n",
      "10100/13118\n",
      "10200/13118\n",
      "10300/13118\n",
      "10400/13118\n",
      "10500/13118\n",
      "10600/13118\n",
      "10700/13118\n",
      "10800/13118\n",
      "10900/13118\n",
      "11000/13118\n",
      "11100/13118\n",
      "11200/13118\n",
      "11300/13118\n",
      "11400/13118\n",
      "11500/13118\n",
      "11600/13118\n",
      "11700/13118\n",
      "11800/13118\n",
      "11900/13118\n",
      "12000/13118\n",
      "12100/13118\n",
      "12200/13118\n",
      "12300/13118\n",
      "12400/13118\n",
      "12500/13118\n",
      "12600/13118\n",
      "12700/13118\n",
      "12800/13118\n",
      "12900/13118\n",
      "13000/13118\n",
      "13100/13118\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\ku\\\\4-1\\\\nlp\\\\summarization\\\\corpus\\\\13118.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-7118d69091c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'13118.txt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-99145b3d1a8b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(filenames)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0min_filename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mout_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'{outpath}/{in_filename[:-4]}.pickle'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreadfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdialogues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dialogues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#         print(dialogues)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-d2f0cc28b302>\u001b[0m in \u001b[0;36mreadfile\u001b[1;34m(in_filename, inpath)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreadfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0min_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{inpath}\\\\{in_filename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\codecs.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[0;32m    895\u001b[0m         \u001b[1;31m# Force opening of the file in binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\ku\\\\4-1\\\\nlp\\\\summarization\\\\corpus\\\\13118.txt'"
     ]
    }
   ],
   "source": [
    "main(['13118.txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
